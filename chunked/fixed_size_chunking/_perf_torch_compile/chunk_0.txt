
Optimize inference using torch.compile()
This guide aims to provide a benchmark on the inference speed-ups introduced with torch.compile()Â for computer vision models in ðŸ¤— Transformers.
Benefits of torch.compile
Depending on the model and the GPU, torch.compile() yields up to 30% speed-up during inference. To use torch.compile(), simply install any version of torch above 2.0. 
Compiling a model takes time, so it's useful if you are compiling the model only once instead of every time you infer.
To compile an