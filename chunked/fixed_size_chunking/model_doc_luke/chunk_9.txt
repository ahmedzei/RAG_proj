tion". Please refer to the example code of each head models.
Usage example:
thon

from transformers import LukeTokenizer, LukeModel, LukeForEntityPairClassification
model = LukeModel.from_pretrained("studio-ousia/luke-base")
tokenizer = LukeTokenizer.from_pretrained("studio-ousia/luke-base")

Example 1: Computing the contextualized entity representation corresponding to the entity mention "Beyoncé"

text = "Beyoncé lives in Los Angeles."
entity_spans = [(0, 7)]  # character-based entity span corresponding t