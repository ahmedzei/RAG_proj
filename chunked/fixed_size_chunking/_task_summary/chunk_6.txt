s, and cars. We can ask our virtual assistants to play music, set reminders, and tell us the weather. 
But one of the key challenges Transformer architectures have helped with is in low-resource languages. By pretraining on large amounts of speech data, finetuning the model on only one hour of labeled speech data in a low-resource language can still produce high-quality results compared to previous ASR systems trained on 100x more labeled data.

from transformers import pipeline
transcriber = pipeline(task=