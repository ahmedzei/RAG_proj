n is released through pip, ensure that you are doing one of the following:

When loading the model, ensure that trust_remote_code=True is passed as an argument of the from_pretrained() function.

Update your local transformers to the development version: pip uninstall -y transformers && pip install git+https://github.com/huggingface/transformers. The previous command is an alternative to cloning and installing from the source.

thon

from transformers import AutoModelForCausalLM, AutoTokenizer
model = AutoM