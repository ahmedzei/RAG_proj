_file).astype(
                 str
             )  # be sure to make your table data text only
             encoding = self.tokenizer(
                 table=table,
                 queries=item.question,
                 answer_coordinates=item.answer_coordinates,
                 answer_text=item.answer_text,
                 truncation=True,
                 padding="max_length",
                 return_tensors="tf",
             )
             # remove the batch dimension which the tokenizer adds by de