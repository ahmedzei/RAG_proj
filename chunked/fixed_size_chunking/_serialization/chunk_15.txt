locally, save the model's weights and tokenizer files in the same directory (e.g. local-pt-checkpoint), 
then export it to ONNX by pointing the --model argument of the transformers.onnx package to the desired directory:

python -m transformers.onnx --model=local-pt-checkpoint onnx/