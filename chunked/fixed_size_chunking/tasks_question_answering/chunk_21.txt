("my_awesome_qa_model")
inputs = tokenizer(question, context, return_tensors="pt")

Pass your inputs to the model and return the logits:

import torch
from transformers import AutoModelForQuestionAnswering
model = AutoModelForQuestionAnswering.from_pretrained("my_awesome_qa_model")
with torch.no_grad():
     outputs = model(**inputs)

Get the highest probability from the model output for the start and end positions:

answer_start_index = outputs.start_logits.argmax()
answer_end_index = outputs.end_logits.ar