 sentence in sentences], return_tensors="pt", padding=True)
output_sequences = model.generate(
     input_ids=inputs["input_ids"],
     attention_mask=inputs["attention_mask"],
     do_sample=False,  # disable sampling to test if batching affects output
 )
print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))
['Das Haus ist wunderbar.', 'Ich arbeite gerne in NYC.']

Because T5 has been trained with the span-mask denoising objective,
it can be used to predict the sentinel (masked-out) tok