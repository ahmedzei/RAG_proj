 TPU.
A notebook for how to finetune T5 for summarization in PyTorch and track experiments with WandB. ðŸŒŽ
A blog post on Distributed Training: Train BART/T5 for Summarization using ðŸ¤— Transformers and Amazon SageMaker.
[T5ForConditionalGeneration] is supported by this example script and notebook.
[TFT5ForConditionalGeneration] is supported by this example script and notebook.
[FlaxT5ForConditionalGeneration] is supported by this example script.
Summarization chapter of the ðŸ¤— Hugging Face course.
Summarization