ens and the real masked tokens. Each
sentinel token represents a unique mask token for this sentence and should start with <extra_id_0>,
<extra_id_1>,  up to <extra_id_99>. As a default, 100 sentinel tokens are available in
[T5Tokenizer].
For instance, the sentence "The cute dog walks in the park" with the masks put on "cute dog" and "the" should be
processed as follows:
thon

from transformers import T5Tokenizer, T5ForConditionalGeneration
tokenizer = T5Tokenizer.from_pretrained("google-t5/t5-small")
model