Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering
summarization, question answering, text classification, and more. To facilitate future work on transfer learning for
NLP, we release our dataset, pre-trained models, and code.
All checkpoints can be found on the hub.
This model was contributed by thomwolf. The original code can be found here.
Usage tips

T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and fo