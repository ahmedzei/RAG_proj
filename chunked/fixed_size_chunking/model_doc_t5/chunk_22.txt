eration.GenerationMixin.generate]. This
method takes care of encoding the input and feeding the encoded hidden states via cross-attention layers to the decoder
and auto-regressively generates the decoder output. Check out this blog post to know all the details about generating text with Transformers.
There's also this blog post which explains how
generation works in general in encoder-decoder models.
thon

from transformers import T5Tokenizer, T5ForConditionalGeneration
tokenizer = T5Tokenizer.from_pretrain