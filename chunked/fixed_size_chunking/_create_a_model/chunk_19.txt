DistilBertTokenizer] class:

from transformers import DistilBertTokenizer
slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert/distilbert-base-uncased")

Create a fast tokenizer with the [DistilBertTokenizerFast] class:

from transformers import DistilBertTokenizerFast
fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert/distilbert-base-uncased")

By default, [AutoTokenizer] will try to load a fast tokenizer. You can disable this behavior by setting use_fast=False in from_pretrai