.train()  # doctest: +SKIP

For tasks - like translation or summarization - that use a sequence-to-sequence model, use the [Seq2SeqTrainer] and [Seq2SeqTrainingArguments] classes instead.

You can customize the training loop behavior by subclassing the methods inside [Trainer]. This allows you to customize features such as the loss function, optimizer, and scheduler. Take a look at the [Trainer] reference for which methods can be subclassed. 
The other way to customize the training loop is by using Callback