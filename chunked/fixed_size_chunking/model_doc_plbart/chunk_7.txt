rtForConditionalGeneration.from_pretrained("uclanlp/plbart-python-en_XX")
translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id["en_XX"])
tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
"Returns the maximum value of a b c."

Resources

Text classification task guide
Causal language modeling task guide
Translation task guide
Summarization task guide

PLBartConfig
[[autodoc]] PLBartConfig
PLBartTokenizer
[[autodoc]] PLBartTokenizer
    - build_inp