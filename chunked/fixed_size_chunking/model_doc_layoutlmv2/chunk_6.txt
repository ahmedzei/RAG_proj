v2 adds both a relative 1D attention bias as well as a spatial 2D attention bias to the attention scores in
  the self-attention layers. Details can be found on page 5 of the paper.
Demo notebooks on how to use the LayoutLMv2 model on RVL-CDIP, FUNSD, DocVQA, CORD can be found here.
LayoutLMv2 uses Facebook AI's Detectron2 package for its visual
  backbone. See this link for installation
  instructions.
In addition to input_ids, [~LayoutLMv2Model.forward] expects 2 additional inputs, namely
  image and bbox