ing it easier to fit large models onto GPUs with limited memory.
Make sure you have bitsandbytes and ðŸ¤— Accelerate installed:
```bash
these versions support 8-bit and 4-bit
pip install bitsandbytes>=0.39.0 accelerate>=0.20.0
install Transformers
pip install transformers

4-bit
To load a model in 4-bit for inference, use the load_in_4bit parameter. The device_map parameter is optional, but we recommend setting it to "auto" to allow ðŸ¤— Accelerate to automatically and efficiently allocate the model given the ava