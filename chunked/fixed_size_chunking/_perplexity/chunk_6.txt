e. The downside is that it requires a separate forward pass for each token in the corpus. A good
practical compromise is to employ a strided sliding window, moving the context by larger strides rather than sliding by
1 token a time. This allows computation to proceed much faster while still giving the model a large context to make
predictions at each step.
Example: Calculating perplexity with GPT-2 in ðŸ¤— Transformers
Let's demonstrate this process with GPT-2.
thon
from transformers import GPT2LMHeadModel, GP