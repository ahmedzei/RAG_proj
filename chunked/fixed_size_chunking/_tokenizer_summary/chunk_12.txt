t you love ğŸ¤— Transformers? We sure do.")
["â–Don", "'", "t", "â–you", "â–love", "â–", "ğŸ¤—", "â–", "Transform", "ers", "?", "â–We", "â–sure", "â–do", "."]

We'll get back to the meaning of those "â–" when we look at SentencePiece. As one can see,
the rare word "Transformers" has been split into the more frequent subwords "Transform" and "ers".
Let's now look at how the different subword tokenization algorithms work. Note that all of those tokenization
algorithms rely on some form of training which is usually done on t