 the examples in the batch
     for i in range(len(questions)):
         cls_index = encoding["input_ids"][i].index(tokenizer.cls_token_id)
         # find the position of the answer in example's words
         words_example = [word.lower() for word in words[i]]
         answer = answers[i]
         match, word_idx_start, word_idx_end = subfinder(words_example, answer.lower().split())
         if match:
             # if match is found, use token_type_ids to find where words start in the encoding
          