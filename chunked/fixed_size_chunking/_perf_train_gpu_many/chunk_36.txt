ing none of the models supports full-PP. GPT2 and T5 models have naive MP support. 
The main obstacle is being unable to convert the models to nn.Sequential and have all the inputs to be Tensors. This 
is because currently the models include many features that make the conversion very complicated, and will need to be removed to accomplish that.
DeepSpeed and Megatron-LM integrations are available in ðŸ¤— Accelerate
Other approaches:
DeepSpeed, Varuna and SageMaker use the concept of an Interleaved Pipeline

He