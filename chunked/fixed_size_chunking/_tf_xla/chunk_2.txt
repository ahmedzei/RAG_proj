ed-up is very much model-dependent, for TensorFlow text generation models inside ðŸ¤— Transformers, we noticed a speed-up of ~100x. This document will explain how you can use XLA for these models to get the maximum amount of performance. Weâ€™ll also provide links to additional resources if youâ€™re interested to learn more about the benchmarks and our design philosophy behind the XLA integration.
Running TF functions with XLA
Let us consider the following model in TensorFlow:

import tensorflow as tf
model = tf.k