ueries = [
     ["human face", "rocket", "nasa badge", "star-spangled banner"],
     ["hat", "book", "sunglasses", "camera"],
 ]
inputs = processor(text=text_queries, images=images, return_tensors="pt")

Previously for post-processing you passed the single image's size as a tensor, but you can also pass a tuple, or, in case
of several images, a list of tuples. Let's create predictions for the two examples, and visualize the second one (image_idx = 1).

with torch.no_grad():
     outputs = model(**inputs)
  