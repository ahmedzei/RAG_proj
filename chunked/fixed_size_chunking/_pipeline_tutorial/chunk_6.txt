ver, there are some ways to optimize them for larger workloads than experimentation. See the following guides that dive into iterating over whole datasets or using pipelines in a webserver:
of the docs:
* Using pipelines on a dataset
* Using pipelines for a webserver
Parameters
[pipeline] supports many parameters; some are task specific, and some are general to all pipelines.
In general, you can specify parameters anywhere you want:

transcriber = pipeline(model="openai/whisper-large-v2", my_parameter=1)
ou