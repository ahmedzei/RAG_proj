aining objects to the [~accelerate.Accelerator.prepare] method. This includes your training and evaluation DataLoaders, a model and an optimizer:

train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
     train_dataloader, eval_dataloader, model, optimizer
 )

Backward
The last addition is to replace the typical loss.backward() in your training loop with ðŸ¤— Accelerate's [~accelerate.Accelerator.backward]method:

for epoch in range(num_epochs):
     for batch in train_dataloader:
       