 ResNetv2 in terms of architecture, except that: 1) all batch normalization layers are replaced by group normalization,
2) weight standardization is used for convolutional layers. The authors show that the combination of both is useful for training with large batch sizes, and has a significant
impact on transfer learning.

Resources
A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with BiT.

[BitForImageClassification] is supported by this example script and n