rmers import TFAutoModelForSequenceClassification
from tensorflow.keras.optimizers import Adam
Load and compile our model
model = TFAutoModelForSequenceClassification.from_pretrained("google-bert/bert-base-cased")
Lower learning rates are often better for fine-tuning transformers
model.compile(optimizer=Adam(3e-5))  # No loss argument!
model.fit(tokenized_data, labels)

You don't have to pass a loss argument to your models when you compile() them! Hugging Face models automatically
choose a loss that is appr