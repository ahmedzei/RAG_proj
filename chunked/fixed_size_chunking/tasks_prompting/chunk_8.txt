is additional fine-tuning makes them a better choice for many NLP tasks.  
Let's illustrate some simple prompts that you can use with tiiuae/falcon-7b-instruct 
to solve some common NLP tasks.
NLP tasks
First, let's set up the environment: 

pip install -q transformers accelerate
Next, let's load the model with the appropriate pipeline ("text-generation"): 
thon

from transformers import pipeline, AutoTokenizer
import torch
torch.manual_seed(0) # doctest: +IGNORE_RESULT
model = "tiiuae/falcon-7b-instruct"
t