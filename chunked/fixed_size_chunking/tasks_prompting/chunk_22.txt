 for LLMs, and achieving good results often requires applying advanced prompting techniques, like 
Chain-of-though.
Let's try if we can make a model reason about a simple arithmetics task with a basic prompt: 
thon

torch.manual_seed(5) # doctest: +IGNORE_RESULT
prompt = """There are 5 groups of students in the class. Each group has 4 students. How many students are there in the class?"""
sequences = pipe(
     prompt,
     max_new_tokens=30,
     do_sample=True,
     top_k=10,
     return_full_text = False