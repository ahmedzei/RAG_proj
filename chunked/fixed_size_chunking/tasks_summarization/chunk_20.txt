, model=checkpoint, return_tensors="tf")

Evaluate
Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ðŸ¤— Evaluate library. For this task, load the ROUGE metric (see the ðŸ¤— Evaluate quick tour to learn more about how to load and compute a metric):

import evaluate
rouge = evaluate.load("rouge")

Then create a function that passes your predictions and labels to [~evaluate.EvaluationModule.compute] to calculate the ROUGE 