ables the user to create a chat bot in just 10 lines of code as shown on DialoGPT's model card.

Training:
In order to train or fine-tune DialoGPT, one can use causal language modeling training. To cite the official paper: We
follow the OpenAI GPT-2 to model a multiturn dialogue session as a long text and frame the generation task as language
modeling. We first concatenate all dialog turns within a dialogue session into a long text x_1,, x_N (N is the
sequence length), ended by the end-of-text token. For mo