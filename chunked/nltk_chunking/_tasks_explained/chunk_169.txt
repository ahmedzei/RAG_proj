Positional encodings are added to the token embeddings to indicate the position of each token in the sequence.