The paper aims at creating a single unified foundation model which can work across vision, language
as well as vision-and-language multimodal tasks.