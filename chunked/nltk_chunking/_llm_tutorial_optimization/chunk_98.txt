Long story short, the default self-attention algorithm quickly becomes prohibitively memory-expensive for large input contexts.