CLIP
(Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs.