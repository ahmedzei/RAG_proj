By default, in training mode, the BetterTransformer integration drops the mask support and can only be used for training that does not require a padding mask for batched training.