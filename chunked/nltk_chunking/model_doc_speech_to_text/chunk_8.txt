It's a transformer-based seq2seq model, so the transcripts/translations are generated autoregressively.