Transformers supports several quantization schemes to help you run inference with large language models (LLMs) and finetune adapters on quantized models.