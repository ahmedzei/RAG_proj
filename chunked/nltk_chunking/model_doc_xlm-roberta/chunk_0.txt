
XLM-RoBERTa

Overview
The XLM-RoBERTa model was proposed in Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.