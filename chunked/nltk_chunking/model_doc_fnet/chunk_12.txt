The model was trained with 
maximum sequence length 512 which includes pad tokens.