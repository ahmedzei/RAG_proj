This is where things start getting complicated, and
part of the reason each model has its own tokenizer type.