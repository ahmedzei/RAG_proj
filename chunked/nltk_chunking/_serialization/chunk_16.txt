Exporting a ðŸ¤— Transformers model to ONNX with CLI
To export a ðŸ¤— Transformers model to ONNX, first install an extra dependency:

pip install optimum[exporters]
To check out all available arguments, refer to the ðŸ¤— Optimum docs, 
or view help in command line:

optimum-cli export onnx --help
To export a model's checkpoint from the ðŸ¤— Hub, for example, distilbert/distilbert-base-uncased-distilled-squad, run the following command: 

optimum-cli export onnx --model distilbert/distilbert-base-uncased-distilled-squad distilbert_base_uncased_squad_onnx/
You should see the logs indicating progress and showing where the resulting model.onnx is saved, like this:

Validating ONNX model distilbert_base_uncased_squad_onnx/model.onnx
    -[âœ“] ONNX model output names match reference model (start_logits, end_logits)
    - Validating ONNX Model output "start_logits":
        -[âœ“] (2, 16) matches (2, 16)
        -[âœ“] all values close (atol: 0.0001)
    - Validating ONNX Model output "end_logits":
        -[âœ“] (2, 16) matches (2, 16)
        -[âœ“] all values close (atol: 0.0001)
The ONNX export succeeded and the exported model was saved at: distilbert_base_uncased_squad_onnx
The example above illustrates exporting a checkpoint from ðŸ¤— Hub.