This enables loading larger models you normally wouldn't be able to fit into memory, and speeding up inference.