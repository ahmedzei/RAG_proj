The
[MgpstrProcessor] wraps [ViTImageProcessor] and [MgpstrTokenizer]
into a single instance to both extract the input features and decode the predicted token ids.

Step-by-step Optical Character Recognition (OCR)

from transformers import MgpstrProcessor, MgpstrForSceneTextRecognition
import requests
from PIL import Image
processor = MgpstrProcessor.from_pretrained('alibaba-damo/mgp-str-base')
model = MgpstrForSceneTextRecognition.from_pretrained('alibaba-damo/mgp-str-base')
load image from the IIIT-5k dataset
url = "https://i.postimg.cc/ZKwLg2Gw/367-14.png"
image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
pixel_values = processor(images=image, return_tensors="pt").pixel_values
outputs = model(pixel_values)
generated_text = processor.batch_decode(outputs.logits)['generated_text']

MgpstrConfig
[[autodoc]] MgpstrConfig
MgpstrTokenizer
[[autodoc]] MgpstrTokenizer
    - save_vocabulary
MgpstrProcessor
[[autodoc]] MgpstrProcessor
    - call
    - batch_decode
MgpstrModel
[[autodoc]] MgpstrModel
    - forward
MgpstrForSceneTextRecognition
[[autodoc]] MgpstrForSceneTextRecognition
    - forward.