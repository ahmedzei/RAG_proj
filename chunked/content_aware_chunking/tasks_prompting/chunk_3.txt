You'll learn:

Basics of prompting
Best practices of LLM prompting
Advanced prompting techniques: few-shot prompting and chain-of-thought
When to fine-tune instead of prompting

Prompt engineering is only a part of the LLM output optimization process. Another essential component is choosing the 
optimal text generation strategy. You can customize how your LLM selects each of the subsequent tokens when generating 
the text without modifying any of the trainable parameters.