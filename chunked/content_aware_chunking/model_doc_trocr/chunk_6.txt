The
[TrOCRProcessor] wraps [ViTImageProcessor/DeiTImageProcessor] and [RobertaTokenizer/XLMRobertaTokenizer]
into a single instance to both extract the input features and decode the predicted token ids.

Step-by-step Optical Character Recognition (OCR)

``` py

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import requests
from PIL import Image
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")
load image from the IAM dataset
url = "https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg"
image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
pixel_values = processor(image, return_tensors="pt").pixel_values
generated_ids = model.generate(pixel_values)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

See the model hub to look for TrOCR checkpoints.
TrOCRConfig
[[autodoc]] TrOCRConfig
TrOCRProcessor
[[autodoc]] TrOCRProcessor
    - call
    - from_pretrained
    - save_pretrained
    - batch_decode
    - decode
TrOCRForCausalLM
[[autodoc]] TrOCRForCausalLM
     - forward.