With a similar inference
time, SEW reduces word error rate by 25-50% across different model sizes.
This model was contributed by anton-l.
Usage tips

SEW is a speech model that accepts a float array corresponding to the raw waveform of the speech signal.
SEWForCTC is fine-tuned using connectionist temporal classification (CTC) so the model output has to be decoded using
  [Wav2Vec2CTCTokenizer].

Resources

Audio classification task guide
Automatic speech recognition task guide

SEWConfig
[[autodoc]] SEWConfig
SEWModel
[[autodoc]] SEWModel
    - forward
SEWForCTC
[[autodoc]] SEWForCTC
    - forward
SEWForSequenceClassification
[[autodoc]] SEWForSequenceClassification
    - forward.