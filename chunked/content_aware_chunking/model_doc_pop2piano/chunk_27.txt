audio1, sr1 = librosa.load("", sr=44100)
audio2, sr2 = librosa.load("", sr=44100)
model = Pop2PianoForConditionalGeneration.from_pretrained("sweetcocoa/pop2piano")
processor = Pop2PianoProcessor.from_pretrained("sweetcocoa/pop2piano")
inputs = processor(audio=[audio1, audio2], sampling_rate=[sr1, sr2], return_attention_mask=True, return_tensors="pt")
Since we now generating in batch(2 audios) we must pass the attention_mask
model_output = model.generate(
     input_features=inputs["input_features"],
     attention_mask=inputs["attention_mask"],
     composer="composer1",
 )
tokenizer_output = processor.batch_decode(
     token_ids=model_output, feature_extractor_output=inputs
 )["pretty_midi_objects"]
Since we now have 2 generated MIDI files
tokenizer_output[0].write("./Outputs/midi_output1.mid")
tokenizer_output[1].write("./Outputs/midi_output2.mid")

Example of processing multiple audio files in batch (Using Pop2PianoFeatureExtractor and Pop2PianoTokenizer):

thon

import librosa
from transformers import Pop2PianoForConditionalGeneration, Pop2PianoFeatureExtractor, Pop2PianoTokenizer
feel free to change the sr to a suitable value.