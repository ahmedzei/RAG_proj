Seqeval actually produces several scores: precision, recall, F1, and accuracy.

import evaluate
seqeval = evaluate.load("seqeval")

Get the NER labels first, and then create a function that passes your true predictions and true labels to [~evaluate.EvaluationModule.compute] to calculate the scores:

import numpy as np
labels = [label_list[i] for i in example[f"ner_tags"]]
def compute_metrics(p):
     predictions, labels = p
     predictions = np.argmax(predictions, axis=2)

     true_predictions = [
         [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
         for prediction, label in zip(predictions, labels)
     ]
     true_labels = [
         [label_list[l] for (p, l) in zip(prediction, label) if l != -100]
         for prediction, label in zip(predictions, labels)
     ]
     results = seqeval.compute(predictions=true_predictions, references=true_labels)
     return {
         "precision": results["overall_precision"],
         "recall": results["overall_recall"],
         "f1": results["overall_f1"],
         "accuracy": results["overall_accuracy"],
     }

Your compute_metrics function is ready to go now, and you'll return to it when you setup your training.
Train
Before you start training your model, create a map of the expected ids to their labels with id2label and label2id:

id2label = {
     0: "O",
     1: "B-corporation",
     2: "I-corporation",
     3: "B-creative-work",
     4: "I-creative-work",
     5: "B-group",
     6: "I-group",
     7: "B-location",
     8: "I-location",
     9: "B-person",
     10: "I-person",
     11: "B-product",
     12: "I-product",
 }
label2id = {
     "O": 0,
     "B-corporation": 1,
     "I-corporation": 2,
     "B-creative-work": 3,
     "I-creative-work": 4,
     "B-group": 5,
     "I-group": 6,
     "B-location": 7,
     "I-location": 8,
     "B-person": 9,
     "I-person": 10,
     "B-product": 11,
     "I-product": 12,
 }

If you aren't familiar with finetuning a model with the [Trainer], take a look at the basic tutorial here!

You're ready to start training your model now! Load DistilBERT with [AutoModelForTokenClassification] along with the number of expected labels, and the label mappings:

from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer
model = AutoModelForTokenClassification.from_pretrained(
     "distilbert/distilbert-base-uncased", num_labels=13, id2label=id2label, label2id=label2id
 )

At this point, only three steps remain:

Define your training hyperparameters in [TrainingArguments].