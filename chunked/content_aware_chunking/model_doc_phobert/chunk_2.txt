The original code can be found here.
Usage example
thon

import torch
from transformers import AutoModel, AutoTokenizer
phobert = AutoModel.from_pretrained("vinai/phobert-base")
tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")
INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!
line = "Tôi là sinh_viên trường đại_học Công_nghệ ."
input_ids = torch.tensor([tokenizer.encode(line)])
with torch.no_grad():
     features = phobert(input_ids)  # Models outputs are now tuples
With TensorFlow 2.0+:
from transformers import TFAutoModel
phobert = TFAutoModel.from_pretrained("vinai/phobert-base")

 
PhoBERT implementation is the same as BERT, except for tokenization.