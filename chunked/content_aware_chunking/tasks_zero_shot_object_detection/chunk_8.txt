The processor combines an image processor that prepares the
image for the model by resizing and normalizing it, and a [CLIPTokenizer] that takes care of the text inputs.

text_queries = ["hat", "book", "sunglasses", "camera"]
inputs = processor(text=text_queries, images=im, return_tensors="pt")

Pass the inputs through the model, post-process, and visualize the results.