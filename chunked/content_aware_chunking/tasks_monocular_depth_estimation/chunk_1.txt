In this guide you'll learn how to:

create a depth estimation pipeline
run depth estimation inference by hand

Before you begin, make sure you have all the necessary libraries installed:

pip install -q transformers
Depth estimation pipeline
The simplest way to try out inference with a model supporting depth estimation is to use the corresponding [pipeline].
Instantiate a pipeline from a checkpoint on the Hugging Face Hub:

from transformers import pipeline
checkpoint = "vinvino02/glpn-nyu"
depth_estimator = pipeline("depth-estimation", model=checkpoint)

Next, choose an image to analyze:

from PIL import Image
import requests
url = "https://unsplash.com/photos/HwBAsSbPBDU/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8MzR8fGNhciUyMGluJTIwdGhlJTIwc3RyZWV0fGVufDB8MHx8fDE2Nzg5MDEwODg&force=true&w=640"
image = Image.open(requests.get(url, stream=True).raw)
image

Pass the image to the pipeline.

predictions = depth_estimator(image)

The pipeline returns a dictionary with two entries.