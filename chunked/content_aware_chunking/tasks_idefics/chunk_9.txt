Without a text prompt, the model will start generating text from the 
BOS (beginning-of-sequence) token thus creating a caption.
As image input to the model, you can use either an image object (PIL.Image) or a url from which the image can be retrieved.

prompt = [
     "https://images.unsplash.com/photo-1583160247711-2191776b4b91?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3542&q=80",
 ]
inputs = processor(prompt, return_tensors="pt").to("cuda")
bad_words_ids = processor.tokenizer(["", ""], add_special_tokens=False).input_ids
generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
print(generated_text[0])
A puppy in a flower bed

It is a good idea to include the bad_words_ids in the call to generate to avoid errors arising when increasing 
the max_new_tokens: the model will want to generate a new <image> or <fake_token_around_image> token when there 
is no image being generated by the model.
You can set it on-the-fly as in this guide, or store in the GenerationConfig as described in the Text generation strategies guide.

Prompted image captioning
You can extend image captioning by providing a text prompt, which the model will continue given the image.