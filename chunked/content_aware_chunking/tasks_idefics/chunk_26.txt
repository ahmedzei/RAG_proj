Idefix is running on the ground.",
         "\nUser:",
         "https://static.wikia.nocookie.net/asterix/images/2/25/R22b.gif/revision/latest?cb=20110815073052",
         "And who is that?",
         "\nAssistant:",
     ],
 ]

--batched mode
inputs = processor(prompts, add_end_of_utterance_token=False, return_tensors="pt").to(device)
--single sample mode
inputs = processor(prompts[0], return_tensors="pt").to(device)
Generation args
exit_condition = processor.tokenizer("", add_special_tokens=False).input_ids
bad_words_ids = processor.tokenizer(["", ""], add_special_tokens=False).input_ids
generated_ids = model.generate(**inputs, eos_token_id=exit_condition, bad_words_ids=bad_words_ids, max_length=100)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
for i, t in enumerate(generated_text):
     print(f"{i}:\n{t}\n")

.