pip install -q bitsandbytes sentencepiece accelerate transformers

To run the following examples with a non-quantized version of the model checkpoint you will need at least 20GB of GPU memory.

Loading the model
Let's start by loading the model's 9 billion parameters checkpoint: 

checkpoint = "HuggingFaceM4/idefics-9b"

Just like for other Transformers models, you need to load a processor and the model itself from the checkpoint.