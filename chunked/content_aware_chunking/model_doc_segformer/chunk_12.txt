In that case, reduce_labels should be set to
  False, as loss should also be computed for the background class.
As most models, SegFormer comes in different sizes, the details of which can be found in the table below
  (taken from Table 7 of the original paper).

| Model variant | Depths    | Hidden sizes    | Decoder hidden size | Params (M) | ImageNet-1k Top 1 |
| :---------------: | ------------- | ------------------- | :---------------------: | :------------: | :-------------------: |
| MiT-b0            | [2, 2, 2, 2]  | [32, 64, 160, 256]  | 256                     | 3.7            | 70.5                  |
| MiT-b1            | [2, 2, 2, 2]  | [64, 128, 320, 512] | 256                     | 14.0           | 78.7                  |
| MiT-b2            | [3, 4, 6, 3]  | [64, 128, 320, 512] | 768                     | 25.4           | 81.6                  |
| MiT-b3            | [3, 4, 18, 3] | [64, 128, 320, 512] | 768                     | 45.2           | 83.1                  |
| MiT-b4            | [3, 8, 27, 3] | [64, 128, 320, 512] | 768                     | 62.6           | 83.6                  |
| MiT-b5            | [3, 6, 40, 3] | [64, 128, 320, 512] | 768                     | 82.0           | 83.8                  |
Note that MiT in the above table refers to the Mix Transformer encoder backbone introduced in SegFormer.