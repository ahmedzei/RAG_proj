Usage example
CANINE works on raw characters, so it can be used without a tokenizer:
thon

from transformers import CanineModel
import torch
model = CanineModel.from_pretrained("google/canine-c")  # model pre-trained with autoregressive character loss
text = "hello world"
use Python's built-in ord() function to turn each character into its unicode code point id
input_ids = torch.tensor([[ord(char) for char in text]])
outputs = model(input_ids)  # forward pass
pooled_output = outputs.pooler_output
sequence_output = outputs.last_hidden_state

For batched inference and training, it is however recommended to make use of the tokenizer (to pad/truncate all
sequences to the same length):
thon

from transformers import CanineTokenizer, CanineModel
model = CanineModel.from_pretrained("google/canine-c")
tokenizer = CanineTokenizer.from_pretrained("google/canine-c")
inputs = ["Life is like a box of chocolates.