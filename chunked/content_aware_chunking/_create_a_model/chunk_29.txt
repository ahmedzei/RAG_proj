For example, create a default [Wav2Vec2FeatureExtractor] if you are using Wav2Vec2 for audio classification:

from transformers import Wav2Vec2FeatureExtractor
w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

If you aren't looking for any customization, just use the from_pretrained method to load a model's default feature extractor parameters.

Modify any of the [Wav2Vec2FeatureExtractor] parameters to create your custom feature extractor:

from transformers import Wav2Vec2FeatureExtractor
w2v2_extractor = Wav2Vec2FeatureExtractor(sampling_rate=8000, do_normalize=False)
print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": false,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 8000
}

Processor
For models that support multimodal tasks, ðŸ¤— Transformers offers a processor class that conveniently wraps processing classes such as a feature extractor and a tokenizer into a single object.