To see how 
much it is we load a tiny tensor into the GPU which triggers the kernels to be loaded as well.

import torch
torch.ones((1, 1)).to("cuda")
print_gpu_utilization()
GPU memory occupied: 1343 MB.

We see that the kernels alone take up 1.3GB of GPU memory. Now let's see how much space the model uses.
Load Model
First, we load the google-bert/bert-large-uncased model.