Finally, contributions in this work—including models, code, and a watermark detector—are publicly released and accessible at the link below.
Usage
In the following example, we'll load an Arabic audio sample and an English text sample and convert them into Russian speech and French text.
First, load the processor and a checkpoint of the model:
thon

from transformers import AutoProcessor, SeamlessM4Tv2Model
processor = AutoProcessor.from_pretrained("facebook/seamless-m4t-v2-large")
model = SeamlessM4Tv2Model.from_pretrained("facebook/seamless-m4t-v2-large")

You can seamlessly use this model on text or on audio, to generated either translated text or translated audio.
Here is how to use the processor to process text and audio:
thon

let's load an audio sample from an Arabic speech corpus
from datasets import load_dataset
dataset = load_dataset("arabic_speech_corpus", split="test", streaming=True)
audio_sample = next(iter(dataset))["audio"]
now, process it
audio_inputs = processor(audios=audio_sample["array"], return_tensors="pt")
now, process some English text as well
text_inputs = processor(text = "Hello, my dog is cute", src_lang="eng", return_tensors="pt")

Speech
[SeamlessM4Tv2Model] can seamlessly generate text or speech with few or no changes.