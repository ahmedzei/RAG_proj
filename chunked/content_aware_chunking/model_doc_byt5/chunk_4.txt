As part of our contribution, we release a new set of
pre-trained byte-level Transformer models based on the T5 architecture, as well as all code and data used in our
experiments.
This model was contributed by patrickvonplaten. The original code can be
found here.

ByT5's architecture is based on the T5v1.1 model, refer to T5v1.1's documentation page for the API reference.