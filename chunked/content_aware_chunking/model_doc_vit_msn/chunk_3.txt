For instance,
on ImageNet-1K, with only 5,000 annotated images, our base MSN model achieves 72.4% top-1 accuracy,
and with 1% of ImageNet-1K labels, we achieve 75.7% top-1 accuracy, setting a new state-of-the-art for self-supervised learning on this benchmark.
 
 MSN architecture. Taken from the original paper. 
This model was contributed by sayakpaul. The original code can be found here. 
Usage tips

MSN (masked siamese networks) is a method for self-supervised pre-training of Vision Transformers (ViTs).