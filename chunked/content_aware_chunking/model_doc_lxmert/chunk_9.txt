Further, while the cross-modality encoder
  contains self-attention for each respective modality and cross-attention, only the cross attention is returned and
  both self attention outputs are disregarded.

Resources

Question answering task guide

LxmertConfig
[[autodoc]] LxmertConfig
LxmertTokenizer
[[autodoc]] LxmertTokenizer
LxmertTokenizerFast
[[autodoc]] LxmertTokenizerFast
Lxmert specific outputs
[[autodoc]] models.lxmert.modeling_lxmert.LxmertModelOutput
[[autodoc]] models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput
[[autodoc]] models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput
[[autodoc]] models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput
[[autodoc]] models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput

LxmertModel
[[autodoc]] LxmertModel
    - forward
LxmertForPreTraining
[[autodoc]] LxmertForPreTraining
    - forward
LxmertForQuestionAnswering
[[autodoc]] LxmertForQuestionAnswering
    - forward

TFLxmertModel
[[autodoc]] TFLxmertModel
    - call
TFLxmertForPreTraining
[[autodoc]] TFLxmertForPreTraining
    - call

.