The original code can be found here.
Usage tips

Wav2Vec2-BERT follows the same architecture as Wav2Vec2-Conformer, but employs a causal depthwise convolutional layer and uses as input a mel-spectrogram representation of the audio instead of the raw waveform.
Wav2Vec2-BERT can use either no relative position embeddings, Shaw-like position embeddings, Transformer-XL-like position embeddings, or
  rotary position embeddings by setting the correct config.position_embeddings_type.
Wav2Vec2-BERT also introduces a Conformer-based adapter network instead of a simple convolutional network.

Resources

[Wav2Vec2BertForCTC] is supported by this example script.
You can also adapt these notebooks on how to finetune a speech recognition model in English, and how to finetune a speech recognition model in any language.

[Wav2Vec2BertForSequenceClassification] can be used by adapting this example script.
See also: Audio classification task guide

Wav2Vec2BertConfig
[[autodoc]] Wav2Vec2BertConfig
Wav2Vec2BertProcessor
[[autodoc]] Wav2Vec2BertProcessor
    - call
    - pad
    - from_pretrained
    - save_pretrained
    - batch_decode
    - decode
Wav2Vec2BertModel
[[autodoc]] Wav2Vec2BertModel
    - forward
Wav2Vec2BertForCTC
[[autodoc]] Wav2Vec2BertForCTC
    - forward
Wav2Vec2BertForSequenceClassification
[[autodoc]] Wav2Vec2BertForSequenceClassification
    - forward
Wav2Vec2BertForAudioFrameClassification
[[autodoc]] Wav2Vec2BertForAudioFrameClassification
    - forward
Wav2Vec2BertForXVector
[[autodoc]] Wav2Vec2BertForXVector
    - forward.