However, XLA is not limited to these methods - it can also be used to accelerate any arbitrary tf.function.
Several TensorFlow methods in ðŸ¤— Transformers have been rewritten to be XLA-compatible, including text generation for models such as GPT2, T5 and OPT, as well as speech processing for models such as Whisper.
While the exact amount of speed-up is very much model-dependent, for TensorFlow text generation models inside ðŸ¤— Transformers, we noticed a speed-up of ~100x.