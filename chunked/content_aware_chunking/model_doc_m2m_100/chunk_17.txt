model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors="pt")
loss = model(**model_inputs).loss  # forward pass

Generation
M2M100 uses the eos_token_id as the decoder_start_token_id for generation with the target language id 
being forced as the first generated token.