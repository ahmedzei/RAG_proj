Instantiate a pipeline for automatic speech recognition with your model, and pass your audio file to it:

from transformers import pipeline
transcriber = pipeline("automatic-speech-recognition", model="stevhliu/my_awesome_asr_minds_model")
transcriber(audio_file)
{'text': 'I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER'}

The transcription is decent, but it could be better! Try finetuning your model on more examples to get even better results!

You can also manually replicate the results of the pipeline if you'd like:

Load a processor to preprocess the audio file and transcription and return the input as PyTorch tensors:

from transformers import AutoProcessor
processor = AutoProcessor.from_pretrained("stevhliu/my_awesome_asr_mind_model")
inputs = processor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")

Pass your inputs to the model and return the logits:

from transformers import AutoModelForCTC
model = AutoModelForCTC.from_pretrained("stevhliu/my_awesome_asr_mind_model")
with torch.no_grad():
     logits = model(**inputs).logits

Get the predicted input_ids with the highest probability, and use the processor to decode the predicted input_ids back into text:

import torch
predicted_ids = torch.argmax(logits, dim=-1)
transcription = processor.batch_decode(predicted_ids)
transcription
['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']

.