The following example shows how to get the image-text similarity scores using [AlignProcessor] and [AlignModel].
thon
import requests
import torch
from PIL import Image
from transformers import AlignProcessor, AlignModel
processor = AlignProcessor.from_pretrained("kakaobrain/align-base")
model = AlignModel.from_pretrained("kakaobrain/align-base")
url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)
candidate_labels = ["an image of a cat", "an image of a dog"]
inputs = processor(text=candidate_labels, images=image, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)
this is the image-text similarity score
logits_per_image = outputs.logits_per_image
we can take the softmax to get the label probabilities
probs = logits_per_image.softmax(dim=1)
print(probs)

Resources
A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with ALIGN.

A blog post on ALIGN and the COYO-700M dataset.
A zero-shot image classification demo.
Model card of kakaobrain/align-base model.

If you're interested in submitting a resource to be included here, please feel free to open a Pull Request and we will review it.