To see a more complex template in action, though, let's use the 
mistralai/Mistral-7B-Instruct-v0.1 model.
thon

from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
chat = [
   {"role": "user", "content": "Hello, how are you?"},
   {"role": "assistant", "content": "I'm doing great.