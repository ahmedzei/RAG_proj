Unlike other data collators in ðŸ¤— Transformers, the [DefaultDataCollator] does not apply any additional preprocessing such as padding.

from transformers import DefaultDataCollator
data_collator = DefaultDataCollator()
</pt>
<tf>py
from transformers import DefaultDataCollator
data_collator = DefaultDataCollator(return_tensors="tf")

Train

If you aren't familiar with finetuning a model with the [Trainer], take a look at the basic tutorial here!

You're ready to start training your model now! Load DistilBERT with [AutoModelForQuestionAnswering]:

from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer
model = AutoModelForQuestionAnswering.from_pretrained("distilbert/distilbert-base-uncased")

At this point, only three steps remain:

Define your training hyperparameters in [TrainingArguments].