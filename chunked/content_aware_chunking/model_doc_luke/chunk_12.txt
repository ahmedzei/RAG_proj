Please refer to the example code of each head models.
Usage example:
thon

from transformers import LukeTokenizer, LukeModel, LukeForEntityPairClassification
model = LukeModel.from_pretrained("studio-ousia/luke-base")
tokenizer = LukeTokenizer.from_pretrained("studio-ousia/luke-base")

Example 1: Computing the contextualized entity representation corresponding to the entity mention "Beyoncé"

text = "Beyoncé lives in Los Angeles."
entity_spans = [(0, 7)]  # character-based entity span corresponding to "Beyoncé"
inputs = tokenizer(text, entity_spans=entity_spans, add_prefix_space=True, return_tensors="pt")
outputs = model(**inputs)
word_last_hidden_state = outputs.last_hidden_state
entity_last_hidden_state = outputs.entity_last_hidden_state

Example 2: Inputting Wikipedia entities to obtain enriched contextualized representations

entities = [
     "Beyoncé",
     "Los Angeles",
 ]  # Wikipedia entity titles corresponding to the entity mentions "Beyoncé" and "Los Angeles"
entity_spans = [(0, 7), (17, 28)]  # character-based entity spans corresponding to "Beyoncé" and "Los Angeles"
inputs = tokenizer(text, entities=entities, entity_spans=entity_spans, add_prefix_space=True, return_tensors="pt")
outputs = model(**inputs)
word_last_hidden_state = outputs.last_hidden_state
entity_last_hidden_state = outputs.entity_last_hidden_state

Example 3: Classifying the relationship between two entities using LukeForEntityPairClassification head model

model = LukeForEntityPairClassification.from_pretrained("studio-ousia/luke-large-finetuned-tacred")
tokenizer = LukeTokenizer.from_pretrained("studio-ousia/luke-large-finetuned-tacred")
entity_spans = [(0, 7), (17, 28)]  # character-based entity spans corresponding to "Beyoncé" and "Los Angeles"
inputs = tokenizer(text, entity_spans=entity_spans, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
predicted_class_idx = int(logits[0].argmax())
print("Predicted class:", model.config.id2label[predicted_class_idx])

Resources

A demo notebook on how to fine-tune [LukeForEntityPairClassification] for relation classification
Notebooks showcasing how you to reproduce the results as reported in the paper with the HuggingFace implementation of LUKE
Text classification task guide
Token classification task guide
Question answering task guide
Masked language modeling task guide
Multiple choice task guide

LukeConfig
[[autodoc]] LukeConfig
LukeTokenizer
[[autodoc]] LukeTokenizer
    - call
    - save_vocabulary
LukeModel
[[autodoc]] LukeModel
    - forward
LukeForMaskedLM
[[autodoc]] LukeForMaskedLM
    - forward
LukeForEntityClassification
[[autodoc]] LukeForEntityClassification
    - forward
LukeForEntityPairClassification
[[autodoc]] LukeForEntityPairClassification
    - forward
LukeForEntitySpanClassification
[[autodoc]] LukeForEntitySpanClassification
    - forward
LukeForSequenceClassification
[[autodoc]] LukeForSequenceClassification
    - forward
LukeForMultipleChoice
[[autodoc]] LukeForMultipleChoice
    - forward
LukeForTokenClassification
[[autodoc]] LukeForTokenClassification
    - forward
LukeForQuestionAnswering
[[autodoc]] LukeForQuestionAnswering
    - forward.