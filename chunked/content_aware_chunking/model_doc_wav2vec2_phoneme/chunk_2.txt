Experiments show that
this simple method significantly outperforms prior work which introduced task-specific architectures and used only part
of a monolingually pretrained model.
Relevant checkpoints can be found under https://huggingface.co/models?other=phoneme-recognition.
This model was contributed by patrickvonplaten
The original code can be found here.
Usage tips

Wav2Vec2Phoneme uses the exact same architecture as Wav2Vec2
Wav2Vec2Phoneme is a speech model that accepts a float array corresponding to the raw waveform of the speech signal.
Wav2Vec2Phoneme model was trained using connectionist temporal classification (CTC) so the model output has to be
  decoded using [Wav2Vec2PhonemeCTCTokenizer].
Wav2Vec2Phoneme can be fine-tuned on multiple language at once and decode unseen languages in a single forward pass
  to a sequence of phonemes
By default, the model outputs a sequence of phonemes.