Note that, despite our advice to use key-value caches, your LLM output may be slightly different when you use them.