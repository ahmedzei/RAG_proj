It provides strong gains over previously released multilingual models like mBERT or XLM on downstream tasks like classification, sequence labeling, and question answering.
M2M100
The following M2M100 models can be used for multilingual translation:

facebook/m2m100_418M (Translation)
facebook/m2m100_1.2B (Translation)

In this example, load the facebook/m2m100_418M checkpoint to translate from Chinese to English.