For the test set, the image processor crops and normalizes the images, and only crops the labels because no data augmentation is applied during testing.

def train_transforms(example_batch):
     images = [jitter(x) for x in example_batch["image"]]
     labels = [x for x in example_batch["annotation"]]
     inputs = image_processor(images, labels)
     return inputs
def val_transforms(example_batch):
     images = [x for x in example_batch["image"]]
     labels = [x for x in example_batch["annotation"]]
     inputs = image_processor(images, labels)
     return inputs

To apply the jitter over the entire dataset, use the ðŸ¤— Datasets [~datasets.Dataset.set_transform] function.