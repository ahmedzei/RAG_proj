If there are only pytorch
checkpoints for a particular encoder-decoder model, a workaround is:
thon

a workaround to load from pytorch checkpoint
from transformers import EncoderDecoderModel, TFEncoderDecoderModel
_model = EncoderDecoderModel.from_pretrained("patrickvonplaten/bert2bert-cnn_dailymail-fp16")
_model.encoder.save_pretrained("./encoder")
_model.decoder.save_pretrained("./decoder")
model = TFEncoderDecoderModel.from_encoder_decoder_pretrained(
     "./encoder", "./decoder", encoder_from_pt=True, decoder_from_pt=True
 )
This is only for copying some specific attributes of this particular model.