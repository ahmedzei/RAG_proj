Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)
Here are some potential solutions you can try to lessen memory use:

Reduce the per_device_train_batch_size value in [TrainingArguments].
Try using gradient_accumulation_steps in [TrainingArguments] to effectively increase overall batch size.

Refer to the Performance guide for more details about memory-saving techniques.

Unable to load a saved TensorFlow model
TensorFlow's model.save method will save the entire model - architecture, weights, training configuration - in a single file.