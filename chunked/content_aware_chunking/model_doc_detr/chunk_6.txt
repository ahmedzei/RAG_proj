Next, the
feature map is flattened and transposed to obtain a tensor of shape (batch_size, seq_len, d_model) =
(batch_size, width/32*height/32, 256). So a difference with NLP models is that the sequence length is actually
longer than usual, but with a smaller d_model (which in NLP is typically 768 or higher).
Next, this is sent through the encoder, outputting encoder_hidden_states of the same shape (you can consider
these as image features). Next, so-called object queries are sent through the decoder.